# 云原生技术公开课
# 1. 元原生概念
## 1.1 不可变基础设施
- 传统的发布：ssh链接机器后，上传/修改文件
- 云原生：容器的发布和替换，原容器不再使用
## 1.2 云应用编排理论
- 如何构建自包含、可定制的应用镜像
- 能不能实现应用的快速部署和隔离能力
- 应用基础设施创建和销毁的自动化管理
- 可复制的管控系统和支撑组件
# 2. 容器基本概念
## 2.1 定义
一组进程的集合
## 2.2 特点
### 2.2.1 视图隔离
针对不同进程使用同一个文件系统所造成的问题而言，Linux 和 Unix 操作系统可以通过 chroot 系统调用将子目录变成根目录，达到视图级别的隔离；进程在 chroot 的帮助下可以具有独立的文件系统，对于这样的文件系统进行增删改查不会影响到其他进程
### 2.2.2 资源可限制
因为进程之间相互可见并且可以相互通信，使用 Namespace 技术来实现进程在资源的视图上进行隔离。在 chroot 和 Namespace 的帮助下，进程就能够运行在一个独立的环境下了
### 2.2.3 独立文件系统
但在独立的环境下，进程所使用的还是同一个操作系统的资源，一些进程可能会侵蚀掉整个系统的资源。为了减少进程彼此之间的影响，可以通过 Cgroup 来限制其资源使用率，设置其能够使用的 CPU 以及内存量
# 3. kubernetes核心概念
## 3.1 Pod
## 3.2 Volume
## 3.3 Deployment
## 3.4 Service
## 3.5 Namespace
# 4. Pod和容器设计模式
## 4.1 Pod
## 4.2 容器设计模式：sidecar
# 5. 应用编排和管理核心原理
## 5.1 kubernetes资源对象
- spec：期望的状态
- status：观测到的状态
- labels：识别资源的标签
- annotations：资源的注解
- owenReference：多个资源之间的相互关系
## 5.2 控制器模式
声明式API，而不是命令式API
# 6. Deployment
## 6.1 背景
pod管理面临的问题：
- 如何保证集群中pod可用的数量
- 如何为所有pod更新镜像版本
- 更新过程中，如果保证服务可用性
- 如何快速回滚
## 6.2 架构设计
Deployment只管理不同版本的ReplicaSet，由ReplicaSet来管理具体的Pod副本数，每个ReplicaSet对应Deployment template的一个版本。
# 7. Job和DaemonSet
## 7.2 Job
### 7.2.1 背景
- 我们如何保证 Pod 内进程正确的结束？
- 如何保证进程运行失败后重试？
- 如何管理多个任务，且任务之间有依赖关系？
- 如何并行地运行任务，并管理任务的队列大小？
## 7.4 DaemonSet
### 7.4.1 背景
- 首先如果希望每个节点都运行同样一个 pod 怎么办？
- 如果新节点加入集群的时候，想要立刻感知到它，然后去部署一个 pod，帮助我们初始化一些东西，这个需求如何做？
- 如果有节点退出的时候，希望对应的 pod 会被删除掉，应该怎么操作？
- 如果 pod 状态异常的时候，我们需要及时地监控这个节点异常，然后做一些监控或者汇报的一些动作，那么这些东西运用什么控制器来做？
# 8. 应用配置管理
## 8.1 背景
用一个容器镜像来启动一个 container，其实有很多需要配套的问题待解决：
- 比如说一些可变的配置。因为我们不可能把一些可变的配置写到镜像里面，当这个配置需要变化的时候，可能需要我们重新编译一次镜像，这个肯定是不能接受的；
- 一些敏感信息的存储和使用。比如说应用需要使用一些密码，或者用一些 token；
- 我们容器要访问集群自身。比如我要访问 kube-apiserver，那么本身就有一个身份认证的问题；
- 容器在节点上运行之后，它的资源需求；
- 容器在节点上，它们是共享内核的，那么它的一个安全管控怎么办？
- 容器启动之前的一个前置条件检验。比如说，一个容器启动之前，我可能要确认一下 DNS 服务是不是好用？又或者确认一下网络是不是联通的？那么这些其实就是一些前置的校验。
## 8.2 ConfigMap
## 8.3 Secret
## 8.4 SecretAccount
## 8.5 Resources
## 8.6 SecurityContext
## 8.7 InitContainers
# 9. 应用存储和持久化数据卷
## 9.1 Volumes介绍
### 9.1.1 Persistent Volumes
### 9.1.2 Persistent Volumes Claim
- Static Volume Provisioning
- Dynamic Volume Provisioning
# 10. 应用存储和持久化数据卷：应用快照和拓扑调度
## 10.1 快照背景
在使用存储时，为了提高数据操作的容错性，我们通常有需要对线上数据进行snapshot，以及能快速restore的能力。另外，当需要对线上数据进行快速的复制以及迁移等动作，如进行环境的复制、数据开发等功能时，都可以通过存储快照来满足需求，而 K8s 中通过 CSI Snapshotter controller 来实现存储快照的功能。
## 10.2 snapshot
## 10.3 restore
## 10.4 topology
拓扑是 K8s 集群中为管理的 nodes 划分的一种“位置”关系，意思为：可以通过在 node 的 labels 信息里面填写某一个 node 属于某一个拓扑。
- 地区region
- 可用区available zone
- 单机维度hostname
# 11. 可观测性
## 11.1 背景
首先来看一下，整个需求的来源：当把应用迁移到 Kubernetes 之后，要如何去保障应用的健康与稳定呢？其实很简单，可以从两个方面来进行增强：
- 提高应用的可观测性；
- 提高应用的可恢复能力。
从可观测性上来讲，可以在三个方面来去做增强：
- 应用的健康状态上面，可以实时地进行观测；
- 获取应用的资源使用情况；
- 拿到应用的实时日志，进行问题的诊断与分析。
当出现了问题之后，首先要做的事情是要降低影响的范围，进行问题的调试与诊断。最后当出现问题的时候，理想的状况是：可以通过和 K8s 集成的自愈机制进行完整的恢复。
## 11.2 Liveness 与 Readiness
探测方式：
- httpGet。它是通过发送 http Get 请求来进行判断的，当返回码是 200-399 之间的状态码时，标识这个应用是健康的；
- Exec。它是通过执行容器中的一个命令来判断当前的服务是否是正常的，当命令行的返回结果是 0，则标识容器是健康的；
- tcpSocket。它是通过探测容器的 IP 和 Port 进行 TCP 健康检查，如果这个 TCP 的链接能够正常被建立，那么标识当前这个容器是健康的。
探测结果：
- 第一种是 success，当状态是 success 的时候，表示 container 通过了健康检查，也就是 Liveness probe 或 Readiness probe 是正常的一个状态； 
- 第二种是 Failure，Failure 表示的是这个 container 没有通过健康检查，如果没有通过健康检查的话，那么此时就会进行相应的一个处理，那在 Readiness 处理的一个方式就是通过 service。service 层将没有通过 Readiness 的 pod 进行摘除，而 Liveness 就是将这个 pod 进行重新拉起，或者是删除。 
- 第三种状态是 Unknown，Unknown 是表示说当前的执行的机制没有进行完整的一个执行，可能是因为类似像超时或者像一些脚本没有及时返回，那么此时 Readiness-probe 或 Liveness-probe 会不做任何的一个操作，会等待下一次的机制来进行检验。
适用场景：
- Liveness 指针适用场景是支持那些可以重新拉起的应用，而 Readiness 指针主要应对的是启动之后无法立即对外提供服务的这些应用。
## 11.3 问题诊断
K8s 是整个的一个设计是面向状态机的，它里面通过 yaml 的方式来定义的是一个期望到达的一个状态，而真正这个 yaml 在执行过程中会由各种各样的 controller来负责整体的状态之间的一个转换。
### 11.3.1 Pod 停留在 Pending
### 11.3.2 Pod 停留在 waiting
### 11.3.3 Pod 不断被拉取并且可以看到 crashing
### 11.3.4 Pod 处在 Runing 但是没有正常工作
### 11.3.5 Service 无法正常的工作
## 11.4 应用远程调试
Pod 远程调试

Service 远程调试

调试工具 - kubectl-debug
# 12. 可观测性：监控与日志
监控和日志是大型分布式系统的重要基础设施，监控可以帮助开发者查看系统的运行状态，而日志可以协助问题的排查和诊断。
## 12.1 监控
- 资源监控：比较常见的像 CPU、内存、网络这种资源类的一个指标
- 性能监控：性能监控指的就是 APM 监控，也就是说常见的一些应用性能类的监控指标的检查。通常是通过一些 Hook 的机制在虚拟机层、字节码执行层通过隐式调用，或者是在应用层显示注入，获取更深层次的一个监控指标，一般是用来应用的调优和诊断的。
- 安全监控：类似像越权管理、安全漏洞扫描等等
- 事件监控：K8s 中的一个设计理念，就是基于状态机的一个状态转换。从正常的状态转换成另一个正常的状态的时候，会发生一个 normal 的事件，而从一个正常状态转换成一个异常状态的时候，会发生一个 warning 的事件。事件监控就是可以把 normal 的事件或者是 warning 事件离线到一个数据中心，然后通过数据中心的分析以及报警
监控演进：Heapster->metrics-server
### 12.1.1 Kubernetes 的监控接口标准
Resource Metrice
Custom Metrics
External Metrics
Promethues - 开源社区的监控“标准”
## 12.2 日志
### 12.2.1 分类
- 主机内核的日志
- Runtime 的日志
- 核心组件的日志
- 部署应用的日志
### 12.2.2 采集
- 宿主机文件
- 容器内有日志文件
- 直接写到 stdout
# 13. kubernetes网络策略及策略控制
## 13.1  Kubernetes的容器网络模型
### 13.1.1 约法三章
- 任意两个 pod 之间其实是可以直接通信的，无需经过显式地使用 NAT 来接收数据和地址的转换；
- node 与 pod 之间是可以直接通信的，无需使用明显的地址转换；
- pod 看到自己的 IP 跟别人看见它所用的IP是一样的，中间不能经过转换。
### 13.1.1 四大目标
- 外部世界和 service 之间是怎么通信的
- service 如何与它后端的 pod 通讯
- pod 和 pod 之间调用是怎么做到通信的
- pod 内部容器与容器之间的通信

容器网络方案大体分为 Underlay/Overlay 两大派别：
- Underlay 的标准是它与 Host 网络是同层的，从外在可见的一个特征就是它是不是使用了 Host 网络同样的网段、输入输出基础设备、容器的 IP 地址是不是需要与 Host 网络取得协同（来自同一个中心分配或统一划分）。这就是 Underlay；
- Overlay 不一样的地方就在于它并不需要从 Host 网络的 IPM 的管理的组件去申请IP，一般来说，它只需要跟 Host 网络不冲突，这个 IP 可以自由分配的。
## 13.2 netns探秘
## 13.3 主流网络方案
- Flannel：用户态的udp，内核的Vxlan，host-gw
- Calico
- Canal
- WeaveNet
## 13.4 network policy
# 14. kubernetes service
service 有一个特别的形态就是 Headless Service。service 创建的时候可以指定 clusterIP:None，告诉 K8s 说我不需要 clusterIP。pod 可以直接通过 service_name 用 DNS 的方式解析到所有后端 pod 的 IP 地址，通过 DNS 的 A 记录的方式会解析到所有后端的 Pod 的地址，由客户端选择一个后端的 IP 地址，这个 A 记录会随着 pod 的生命周期变化，返回的 A 记录列表也发生变化，这样就要求客户端应用要从 A 记录把所有 DNS 返回到 A 记录的列表里面 IP 地址中，客户端自己去选择一个合适的地址去访问 pod。

集群外暴露 Service：NodePort/LoadBalancer
# 15. 深入剖析Linux容器
容器是一种轻量级的虚拟化技术，因为它跟虚拟机比起来，它少了一层 hypervisor 层。

对于容器来说，最重要的是怎么保证这个进程所用到的资源是被隔离和被限制住的，在 Linux 内核上面是由 cgroup 和 namespace 这两个技术来保证的。
- namespace 是用来做资源隔离的
- cgroup 主要是做资源限制的。docker 容器有两种 cgroup 驱动：一种是 systemd 的，另外一种是 cgroupfs 的。

基于 overlay 文件系统的容器镜像存储

以 docker+containerd 为例理解容器引擎如何工作的
# 16. 深入理解etcd：基本原理解析
## 16.1 定义
etcd 是一个分布式的、可靠的 key-value 存储系统，它用于存储分布式系统中的关键数据，这个定义非常重要。


一个 etcd 集群，通常会由 3 个或者 5 个节点组成，多个节点之间，通过一个叫做 Raft 一致性算法的方式完成分布式一致性协同，算法会选举出一个主节点作为 leader，由 leader 负责数据的同步与数据的分发，当 leader 出现故障后，系统会自动地选取另一个节点成为 leader，并重新完成数据的同步与分发。客户端在众多的 leader 中，仅需要选择其中的一个就可以完成数据的读写。

在 etcd 整个的架构中，有一个非常关键的概念叫做 quorum，quorum 的定义是 =（n+1）/2，也就是说超过集群中半数节点组成的一个团体，在 3 个节点的集群中，etcd 可以容许 1 个节点故障，也就是只要有任何 2 个节点重合，etcd 就可以继续提供服务。同理，在 5 个节点的集群中，只要有任何 3 个节点重合，etcd 就可以继续提供服务。这也是 etcd 集群高可用的关键。

当我们在允许部分节点故障之后，继续提供服务，这里就需要解决一个非常复杂的问题，即分布式一致性。在 etcd 中，该分布式一致性算法由 Raft 一致性算法完成，这个算法本身是比较复杂的，我们这里就不展开详细介绍了。

但是这里面有一个关键点，它基于一个前提：任意两个 quorum 的成员之间一定会有一个交集，也就是说只要有任意一个 quorum 存活，其中一定存在某一个节点，它包含着集群中最新的数据。正是基于这个假设，这个一致性算法就可以在一个 quorum 之间采用这份最新的数据去完成数据的同步，从而保证整个集群向前衍进的过程中其数据保持一致。
## 16.2 API
- 第一组是 Put 与 Delete。 put 与 delete 的操作都非常简单，只需要提供一个 key 和一个 value，就可以向集群中写入数据了，那么在删除数据的时候，只需要提供 key 就可以了；
- 第二组操作是查询操作。查询操作 etcd 支持两种类型的查询：第一种是指定单个 key 的查询，第二种是指定的一个 key 的范围；
- 第三组操作：etcd 启动了 Watch 的机制，也就是我们前面提到的用于实现增量的数据更新，watch 也是有两种使用方法，第一种是指定单个 key 的 Watch，另一种是指定一个 key 的前缀。在实际应用场景的使用过程中，经常采用第二种；
- 第四组：API 是 etcd 提供的一个事务操作，可以通过指定某些条件，当条件成立的时候执行一组操作。当条件不成立的时候执行另外一组操作；
- 第五组是 Leases 接口。Leases 接口是分布式系统中常用的一种设计模式。
## 16.3 数据版本号机制
要正确使用 etcd 的 API，必须要知道内部对应数据版本号的基本原理。

- 首先 etcd 中有个 term 的概念，代表的是整个集群 Leader 的标志。当集群发生 Leader 切换，比如说 Leader 节点故障，或者说 Leader 节点网络出现问题，再或者是将整个集群停止后再次拉起，这个时候都会发生 Leader 的切换。当 Leader 切换的时候，term 的值就会 +1。
- 第二个版本号叫做 revision，revision 代表的是全局数据的版本。当数据发生变更，包括创建、修改、删除，revision 对应的都会 +1。在任期内，revision 都可以保持全局单调递增的更改。正是 revision 的存在才使得 etcd 既可以支持数据的 MVCC，也可以支持数据的 Watch。
- 对于每一个 KeyValue 数据，etcd 中都记录了三个版本：
  - 第一个版本叫做 create_revision，是 KeyValue 在创建的时候生成的版本号；
  - 第二个叫做 mod_revision，是其数据被操作的时候对应的版本号；
  - 第三个 version 就是一个计数器，代表了 KeyValue 被修改了多少次。
## 16.4 etcd mvcc & streaming watch
在 etcd 中所有的数据都存储在一个 b+tree 中。b+tree 是保存在磁盘中，并通过 mmap 的方式映射到内存用来查询操作。

在 b+tree 中，维护着 revision 到 value 的映射关系。也就是说当指定 revision 查询数据的时候，就可以通过该 b+tree 直接返回数据。当我们通过 watch 来订阅数据的时候，也可以通过这个 b+tree 维护的 revision 到 value 映射关系，从而通过指定的 revision 开始遍历这个 b+tree，拿到所有的数据更新。

同时在 etcd 内部还维护着另外一个 b+tree。它管理着 key 到 revision 的映射关系。当需要查询 Key 对应数据的时候，会通过蓝色方框的 b+tree，将 key 翻译成 revision。再通过灰色框 b+tree 中的 revision 获取到对应的 value。至此就能满足客户端不同的查询场景了。

这里需要提两点：
- 一个数据是有多个版本的；
- 在 etcd 持续运行过程中会不断的发生修改，意味着 etcd 中内存及磁盘的数据都会持续增长。这对资源有限的场景来说是无法接受的。因此在 etcd 中会周期性的运行一个 Compaction 的机制来清理历史数据。对于一个 Key 的历史版本数据，可以选择清理掉。
## 16.5 etcd mini-transactions
## 16.6 etcd lease 的概念及用法
lease 是分布式系统中一个常见的概念，用于代表一个租约。通常情况下，在分布式系统中需要去检测一个节点是否存活的时候，就需要租约机制。

在 etcd 中，允许将多个 key 关联在统一的 lease 之上，这个设计是非常巧妙的，事实上最初的设计也不是这个样子。通过这种方法，将多个 key 绑定在同一个lease对象，可以大幅地减少 lease 对象刷新的时间。试想一下，如果大量的 key 都需要绑定在同一个 lease 对象之上，每一个 key 都去更新这个租约的话，这个 etcd 会产生非常大的压力。通过支持加多个 key 绑定在同一个 lease 之上，它既不失灵活性同时能够大幅改进 etcd 整个系统的性能。
## 16.7 典型的使用场景介绍
元数据存储-Kubernetes

Server Discovery （Naming Service）

Distributed Coordination: leader election

Distributed Coordination 分布式系统并发控制
# 17. 深入理解etcd：etcd性能优化实践
## 17.1 etcd架构
etcd 集群划分成几个核心的部分：例如 Raft 层、 Storage 层，Storage 层内部又分为 treeIndex 层和 boltdb 底层持久化存储 key/value 层。它们的每一层都有可能造成 etcd 的性能损失。

首先来看 Raft 层，Raft 需要通过网络同步数据，网络 IO 节点之间的 RTT 和 / 带宽会影响 etcd 的性能。除此之外，WAL 也受到磁盘 IO 写入速度影响。

再来看 Storage 层，磁盘 IO fdatasync 延迟会影响 etcd 性能，索引层锁的 block 也会影响 etcd 的性能。除此之外，boltdb Tx 的锁以及 boltdb 本身的性能也将大大影响 etcd 的性能。

从其他方面来看，etcd 所在宿主机的内核参数和 grpc api 层的延迟，也将影响 etcd 的性能。
## 17.2 server端
### 17.2.1 硬件部署
server 端在硬件上需要足够的 CPU 和 Memory 来保障 etcd 的运行。其次，作为一个非常依赖于磁盘 IO 的数据库程序，etcd 需要 IO 延迟和吞吐量非常好的 ssd 硬盘，etcd 是一个分布式的 key/value 存储系统，网络条件对它也很重要。最后在部署上，需要尽量将它独立的部署，以防止宿主机的其他程序会对 etcd 的性能造成干扰。

etcd 官方推荐的配置要求信息：https://coreos.com/docs/latest/op-guide/hardware.html
### 17.2.2 软件
etcd 软件分成很多层：
- 首先是针对于 etcd 的内存索引层优化：优化内部锁的使用减少等待时间。 原来的实现方式是遍历内部引 BTree 使用的内部锁粒度比较粗，这个锁很大程度上影响了 etcd 的性能，新的优化减少了这一部分的影响，降低了延迟。
  具体可参照如下链接：https://github.com/coreos/etcd/pull/9511
- 针对于 lease 规模使用的优化：优化了 lease revoke 和过期失效的算法，将原来遍历失效 list 时间复杂度从 O(n) 降为 O(logn)，解决了 lease 规模化使用的问题。
  具体可参照如下链接：https://github.com/coreos/etcd/pull/9418
- 最后是针对于后端 boltdb 的使用优化：将后端的 batch size limit/interval 进行调整，这样就能根据不同的硬件和工作负载进行动态配置，这些参数以前都是固定的保守值。
  具体可参照如下链接：https://github.com/etcd-io/etcd/commit/3faed211e535729a9dc36198a8aab8799099d0f3
- 还有一点是由谷歌工程师优化的完全并发读特性：优化调用 boltdb tx 读写锁使用，提升读性能。
  具体可参照如下链接：https://github.com/etcd-io/etcd/pull/10523
### 17.2.3 基于 segregated hashmap 的 etcd 内部存储 freelist 分配回收新算法
由阿里贡献的一个性能优化，这个性能优化极大地提升了 etcd 内部存储的性能，CNCF文章：https://www.cncf.io/blog/2019/05/09/performance-optimization-of-etcd-in-web-scale-data-scenario/
## 17.3 client 端
etcd server 给客户端提供的几个 API：Put、Get、Watch、Transactions、Leases 很多个操作。保持客户端使用最佳实践，将保证你的 etcd 集群稳定高效运行。

针对于以上的客户端操作，我们总结了几个最佳实践调用：
- 针对于 Put 操作避免使用大 value，精简精简再精简，例如 K8s 下的 crd 使用；
- 其次，etcd 本身适用及存储一些不频繁变动的 key/value 元数据信息。因此客户端在使用上需要避免创建频繁变化的 key/value。这一点例如 K8s下对于新的 node 节点的心跳数据上传就遵循了这一实践；
- 最后，我们需要避免创建大量的 lease，尽量选择复用。例如在 K8s下，event 数据管理：相同 TTL 失效时间的 event 同样会选择类似的 lease 进行复用，而不是创建新的 lease。
# 18. kubernetes调度和资源管理
# 19. 调度器的调度流程和算法介绍
# 20. GPU管理和Device Plugin工作机制
# 21. kubernetes存储架构及插件使用
# 22. 有状态应用编排：StatefulSet
# 23. kubernetesAPI编程范式
# 24. kubernetesAPI变成利器：Operator和OperatorFramework
# 25. kubernetes网络模型进阶
# 26. 理解CNI和CNI插件
# 27. kubernetes安全之访问控制
# 28. 理解容器运行时接口CRI
# 29. 安全容器技术
# 30. 理解RuntimeClass与使用多容器运行时
