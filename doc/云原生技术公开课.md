# 云原生技术公开课
https://developer.aliyun.com/learning/course/572/detail/7781
# 1. 元原生概念
## 1.1 不可变基础设施
- 传统的发布：ssh链接机器后，上传/修改文件
- 云原生：容器的发布和替换，原容器不再使用
## 1.2 云应用编排理论
- 如何构建自包含、可定制的应用镜像
- 能不能实现应用的快速部署和隔离能力
- 应用基础设施创建和销毁的自动化管理
- 可复制的管控系统和支撑组件
# 2. 容器基本概念
## 2.1 定义
一组进程的集合
## 2.2 特点
### 2.2.1 视图隔离
针对不同进程使用同一个文件系统所造成的问题而言，Linux 和 Unix 操作系统可以通过 chroot 系统调用将子目录变成根目录，达到视图级别的隔离；进程在 chroot 的帮助下可以具有独立的文件系统，对于这样的文件系统进行增删改查不会影响到其他进程
### 2.2.2 资源可限制
因为进程之间相互可见并且可以相互通信，使用 Namespace 技术来实现进程在资源的视图上进行隔离。在 chroot 和 Namespace 的帮助下，进程就能够运行在一个独立的环境下了
### 2.2.3 独立文件系统
但在独立的环境下，进程所使用的还是同一个操作系统的资源，一些进程可能会侵蚀掉整个系统的资源。为了减少进程彼此之间的影响，可以通过 Cgroup 来限制其资源使用率，设置其能够使用的 CPU 以及内存量
# 3. kubernetes核心概念
## 3.1 Pod
## 3.2 Volume
## 3.3 Deployment
## 3.4 Service
## 3.5 Namespace
# 4. Pod和容器设计模式
## 4.1 Pod
## 4.2 容器设计模式：sidecar
# 5. 应用编排和管理核心原理
## 5.1 kubernetes资源对象
- spec：期望的状态
- status：观测到的状态
- labels：识别资源的标签
- annotations：资源的注解
- owenReference：多个资源之间的相互关系
## 5.2 控制器模式
声明式API，而不是命令式API
# 6. Deployment
## 6.1 背景
pod管理面临的问题：
- 如何保证集群中pod可用的数量
- 如何为所有pod更新镜像版本
- 更新过程中，如果保证服务可用性
- 如何快速回滚
## 6.2 架构设计
Deployment只管理不同版本的ReplicaSet，由ReplicaSet来管理具体的Pod副本数，每个ReplicaSet对应Deployment template的一个版本。
# 7. Job和DaemonSet
## 7.2 Job
### 7.2.1 背景
- 我们如何保证 Pod 内进程正确的结束？
- 如何保证进程运行失败后重试？
- 如何管理多个任务，且任务之间有依赖关系？
- 如何并行地运行任务，并管理任务的队列大小？
## 7.4 DaemonSet
### 7.4.1 背景
- 首先如果希望每个节点都运行同样一个 pod 怎么办？
- 如果新节点加入集群的时候，想要立刻感知到它，然后去部署一个 pod，帮助我们初始化一些东西，这个需求如何做？
- 如果有节点退出的时候，希望对应的 pod 会被删除掉，应该怎么操作？
- 如果 pod 状态异常的时候，我们需要及时地监控这个节点异常，然后做一些监控或者汇报的一些动作，那么这些东西运用什么控制器来做？
# 8. 应用配置管理
## 8.1 背景
用一个容器镜像来启动一个 container，其实有很多需要配套的问题待解决：
- 比如说一些可变的配置。因为我们不可能把一些可变的配置写到镜像里面，当这个配置需要变化的时候，可能需要我们重新编译一次镜像，这个肯定是不能接受的；
- 一些敏感信息的存储和使用。比如说应用需要使用一些密码，或者用一些 token；
- 我们容器要访问集群自身。比如我要访问 kube-apiserver，那么本身就有一个身份认证的问题；
- 容器在节点上运行之后，它的资源需求；
- 容器在节点上，它们是共享内核的，那么它的一个安全管控怎么办？
- 容器启动之前的一个前置条件检验。比如说，一个容器启动之前，我可能要确认一下 DNS 服务是不是好用？又或者确认一下网络是不是联通的？那么这些其实就是一些前置的校验。
## 8.2 ConfigMap
## 8.3 Secret
## 8.4 SecretAccount
## 8.5 Resources
## 8.6 SecurityContext
## 8.7 InitContainers
# 9. 应用存储和持久化数据卷
## 9.1 Volumes介绍
### 9.1.1 Persistent Volumes
### 9.1.2 Persistent Volumes Claim
- Static Volume Provisioning
- Dynamic Volume Provisioning
# 10. 应用存储和持久化数据卷：应用快照和拓扑调度
## 10.1 快照背景
在使用存储时，为了提高数据操作的容错性，我们通常有需要对线上数据进行snapshot，以及能快速restore的能力。另外，当需要对线上数据进行快速的复制以及迁移等动作，如进行环境的复制、数据开发等功能时，都可以通过存储快照来满足需求，而 K8s 中通过 CSI Snapshotter controller 来实现存储快照的功能。
## 10.2 snapshot
## 10.3 restore
## 10.4 topology
拓扑是 K8s 集群中为管理的 nodes 划分的一种“位置”关系，意思为：可以通过在 node 的 labels 信息里面填写某一个 node 属于某一个拓扑。
- 地区region
- 可用区available zone
- 单机维度hostname
# 11. 可观测性
## 11.1 背景
首先来看一下，整个需求的来源：当把应用迁移到 Kubernetes 之后，要如何去保障应用的健康与稳定呢？其实很简单，可以从两个方面来进行增强：
- 提高应用的可观测性；
- 提高应用的可恢复能力。
从可观测性上来讲，可以在三个方面来去做增强：
- 应用的健康状态上面，可以实时地进行观测；
- 获取应用的资源使用情况；
- 拿到应用的实时日志，进行问题的诊断与分析。
当出现了问题之后，首先要做的事情是要降低影响的范围，进行问题的调试与诊断。最后当出现问题的时候，理想的状况是：可以通过和 K8s 集成的自愈机制进行完整的恢复。
## 11.2 Liveness 与 Readiness
探测方式：
- httpGet。它是通过发送 http Get 请求来进行判断的，当返回码是 200-399 之间的状态码时，标识这个应用是健康的；
- Exec。它是通过执行容器中的一个命令来判断当前的服务是否是正常的，当命令行的返回结果是 0，则标识容器是健康的；
- tcpSocket。它是通过探测容器的 IP 和 Port 进行 TCP 健康检查，如果这个 TCP 的链接能够正常被建立，那么标识当前这个容器是健康的。
探测结果：
- 第一种是 success，当状态是 success 的时候，表示 container 通过了健康检查，也就是 Liveness probe 或 Readiness probe 是正常的一个状态； 
- 第二种是 Failure，Failure 表示的是这个 container 没有通过健康检查，如果没有通过健康检查的话，那么此时就会进行相应的一个处理，那在 Readiness 处理的一个方式就是通过 service。service 层将没有通过 Readiness 的 pod 进行摘除，而 Liveness 就是将这个 pod 进行重新拉起，或者是删除。 
- 第三种状态是 Unknown，Unknown 是表示说当前的执行的机制没有进行完整的一个执行，可能是因为类似像超时或者像一些脚本没有及时返回，那么此时 Readiness-probe 或 Liveness-probe 会不做任何的一个操作，会等待下一次的机制来进行检验。
适用场景：
- Liveness 指针适用场景是支持那些可以重新拉起的应用，而 Readiness 指针主要应对的是启动之后无法立即对外提供服务的这些应用。
## 11.3 问题诊断
K8s 是整个的一个设计是面向状态机的，它里面通过 yaml 的方式来定义的是一个期望到达的一个状态，而真正这个 yaml 在执行过程中会由各种各样的 controller来负责整体的状态之间的一个转换。
### 11.3.1 Pod 停留在 Pending
### 11.3.2 Pod 停留在 waiting
### 11.3.3 Pod 不断被拉取并且可以看到 crashing
### 11.3.4 Pod 处在 Runing 但是没有正常工作
### 11.3.5 Service 无法正常的工作
## 11.4 应用远程调试
Pod 远程调试

Service 远程调试

调试工具 - kubectl-debug
# 12. 可观测性：监控与日志
监控和日志是大型分布式系统的重要基础设施，监控可以帮助开发者查看系统的运行状态，而日志可以协助问题的排查和诊断。
## 12.1 监控
- 资源监控：比较常见的像 CPU、内存、网络这种资源类的一个指标
- 性能监控：性能监控指的就是 APM 监控，也就是说常见的一些应用性能类的监控指标的检查。通常是通过一些 Hook 的机制在虚拟机层、字节码执行层通过隐式调用，或者是在应用层显示注入，获取更深层次的一个监控指标，一般是用来应用的调优和诊断的。
- 安全监控：类似像越权管理、安全漏洞扫描等等
- 事件监控：K8s 中的一个设计理念，就是基于状态机的一个状态转换。从正常的状态转换成另一个正常的状态的时候，会发生一个 normal 的事件，而从一个正常状态转换成一个异常状态的时候，会发生一个 warning 的事件。事件监控就是可以把 normal 的事件或者是 warning 事件离线到一个数据中心，然后通过数据中心的分析以及报警
监控演进：Heapster->metrics-server
### 12.1.1 Kubernetes 的监控接口标准
Resource Metrice
Custom Metrics
External Metrics
Promethues - 开源社区的监控“标准”
## 12.2 日志
### 12.2.1 分类
- 主机内核的日志
- Runtime 的日志
- 核心组件的日志
- 部署应用的日志
### 12.2.2 采集
- 宿主机文件
- 容器内有日志文件
- 直接写到 stdout
# 13. kubernetes网络策略及策略控制
## 13.1  Kubernetes的容器网络模型
### 13.1.1 约法三章
- 任意两个 pod 之间其实是可以直接通信的，无需经过显式地使用 NAT 来接收数据和地址的转换；
- node 与 pod 之间是可以直接通信的，无需使用明显的地址转换；
- pod 看到自己的 IP 跟别人看见它所用的IP是一样的，中间不能经过转换。
### 13.1.1 四大目标
- 外部世界和 service 之间是怎么通信的
- service 如何与它后端的 pod 通讯
- pod 和 pod 之间调用是怎么做到通信的
- pod 内部容器与容器之间的通信

容器网络方案大体分为 Underlay/Overlay 两大派别：
- Underlay 的标准是它与 Host 网络是同层的，从外在可见的一个特征就是它是不是使用了 Host 网络同样的网段、输入输出基础设备、容器的 IP 地址是不是需要与 Host 网络取得协同（来自同一个中心分配或统一划分）。这就是 Underlay；
- Overlay 不一样的地方就在于它并不需要从 Host 网络的 IPM 的管理的组件去申请IP，一般来说，它只需要跟 Host 网络不冲突，这个 IP 可以自由分配的。
## 13.2 netns探秘
## 13.3 主流网络方案
- Flannel：用户态的udp，内核的Vxlan，host-gw
- Calico
- Canal
- WeaveNet
## 13.4 network policy
# 14. kubernetes service
service 有一个特别的形态就是 Headless Service。service 创建的时候可以指定 clusterIP:None，告诉 K8s 说我不需要 clusterIP。pod 可以直接通过 service_name 用 DNS 的方式解析到所有后端 pod 的 IP 地址，通过 DNS 的 A 记录的方式会解析到所有后端的 Pod 的地址，由客户端选择一个后端的 IP 地址，这个 A 记录会随着 pod 的生命周期变化，返回的 A 记录列表也发生变化，这样就要求客户端应用要从 A 记录把所有 DNS 返回到 A 记录的列表里面 IP 地址中，客户端自己去选择一个合适的地址去访问 pod。

集群外暴露 Service：NodePort/LoadBalancer
# 15. 深入剖析Linux容器
容器是一种轻量级的虚拟化技术，因为它跟虚拟机比起来，它少了一层 hypervisor 层。

对于容器来说，最重要的是怎么保证这个进程所用到的资源是被隔离和被限制住的，在 Linux 内核上面是由 cgroup 和 namespace 这两个技术来保证的。
- namespace 是用来做资源隔离的
- cgroup 主要是做资源限制的。docker 容器有两种 cgroup 驱动：一种是 systemd 的，另外一种是 cgroupfs 的。

基于 overlay 文件系统的容器镜像存储

以 docker+containerd 为例理解容器引擎如何工作的
# 16. 深入理解etcd：基本原理解析
## 16.1 定义
etcd 是一个分布式的、可靠的 key-value 存储系统，它用于存储分布式系统中的关键数据，这个定义非常重要。


一个 etcd 集群，通常会由 3 个或者 5 个节点组成，多个节点之间，通过一个叫做 Raft 一致性算法的方式完成分布式一致性协同，算法会选举出一个主节点作为 leader，由 leader 负责数据的同步与数据的分发，当 leader 出现故障后，系统会自动地选取另一个节点成为 leader，并重新完成数据的同步与分发。客户端在众多的 leader 中，仅需要选择其中的一个就可以完成数据的读写。

在 etcd 整个的架构中，有一个非常关键的概念叫做 quorum，quorum 的定义是 =（n+1）/2，也就是说超过集群中半数节点组成的一个团体，在 3 个节点的集群中，etcd 可以容许 1 个节点故障，也就是只要有任何 2 个节点重合，etcd 就可以继续提供服务。同理，在 5 个节点的集群中，只要有任何 3 个节点重合，etcd 就可以继续提供服务。这也是 etcd 集群高可用的关键。

当我们在允许部分节点故障之后，继续提供服务，这里就需要解决一个非常复杂的问题，即分布式一致性。在 etcd 中，该分布式一致性算法由 Raft 一致性算法完成，这个算法本身是比较复杂的，我们这里就不展开详细介绍了。

但是这里面有一个关键点，它基于一个前提：任意两个 quorum 的成员之间一定会有一个交集，也就是说只要有任意一个 quorum 存活，其中一定存在某一个节点，它包含着集群中最新的数据。正是基于这个假设，这个一致性算法就可以在一个 quorum 之间采用这份最新的数据去完成数据的同步，从而保证整个集群向前衍进的过程中其数据保持一致。
## 16.2 API
- 第一组是 Put 与 Delete。 put 与 delete 的操作都非常简单，只需要提供一个 key 和一个 value，就可以向集群中写入数据了，那么在删除数据的时候，只需要提供 key 就可以了；
- 第二组操作是查询操作。查询操作 etcd 支持两种类型的查询：第一种是指定单个 key 的查询，第二种是指定的一个 key 的范围；
- 第三组操作：etcd 启动了 Watch 的机制，也就是我们前面提到的用于实现增量的数据更新，watch 也是有两种使用方法，第一种是指定单个 key 的 Watch，另一种是指定一个 key 的前缀。在实际应用场景的使用过程中，经常采用第二种；
- 第四组：API 是 etcd 提供的一个事务操作，可以通过指定某些条件，当条件成立的时候执行一组操作。当条件不成立的时候执行另外一组操作；
- 第五组是 Leases 接口。Leases 接口是分布式系统中常用的一种设计模式。
## 16.3 数据版本号机制
要正确使用 etcd 的 API，必须要知道内部对应数据版本号的基本原理。

- 首先 etcd 中有个 term 的概念，代表的是整个集群 Leader 的标志。当集群发生 Leader 切换，比如说 Leader 节点故障，或者说 Leader 节点网络出现问题，再或者是将整个集群停止后再次拉起，这个时候都会发生 Leader 的切换。当 Leader 切换的时候，term 的值就会 +1。
- 第二个版本号叫做 revision，revision 代表的是全局数据的版本。当数据发生变更，包括创建、修改、删除，revision 对应的都会 +1。在任期内，revision 都可以保持全局单调递增的更改。正是 revision 的存在才使得 etcd 既可以支持数据的 MVCC，也可以支持数据的 Watch。
- 对于每一个 KeyValue 数据，etcd 中都记录了三个版本：
  - 第一个版本叫做 create_revision，是 KeyValue 在创建的时候生成的版本号；
  - 第二个叫做 mod_revision，是其数据被操作的时候对应的版本号；
  - 第三个 version 就是一个计数器，代表了 KeyValue 被修改了多少次。
## 16.4 etcd mvcc & streaming watch
在 etcd 中所有的数据都存储在一个 b+tree 中。b+tree 是保存在磁盘中，并通过 mmap 的方式映射到内存用来查询操作。

在 b+tree 中，维护着 revision 到 value 的映射关系。也就是说当指定 revision 查询数据的时候，就可以通过该 b+tree 直接返回数据。当我们通过 watch 来订阅数据的时候，也可以通过这个 b+tree 维护的 revision 到 value 映射关系，从而通过指定的 revision 开始遍历这个 b+tree，拿到所有的数据更新。

同时在 etcd 内部还维护着另外一个 b+tree。它管理着 key 到 revision 的映射关系。当需要查询 Key 对应数据的时候，会通过蓝色方框的 b+tree，将 key 翻译成 revision。再通过灰色框 b+tree 中的 revision 获取到对应的 value。至此就能满足客户端不同的查询场景了。

这里需要提两点：
- 一个数据是有多个版本的；
- 在 etcd 持续运行过程中会不断的发生修改，意味着 etcd 中内存及磁盘的数据都会持续增长。这对资源有限的场景来说是无法接受的。因此在 etcd 中会周期性的运行一个 Compaction 的机制来清理历史数据。对于一个 Key 的历史版本数据，可以选择清理掉。
## 16.5 etcd mini-transactions
## 16.6 etcd lease 的概念及用法
lease 是分布式系统中一个常见的概念，用于代表一个租约。通常情况下，在分布式系统中需要去检测一个节点是否存活的时候，就需要租约机制。

在 etcd 中，允许将多个 key 关联在统一的 lease 之上，这个设计是非常巧妙的，事实上最初的设计也不是这个样子。通过这种方法，将多个 key 绑定在同一个lease对象，可以大幅地减少 lease 对象刷新的时间。试想一下，如果大量的 key 都需要绑定在同一个 lease 对象之上，每一个 key 都去更新这个租约的话，这个 etcd 会产生非常大的压力。通过支持加多个 key 绑定在同一个 lease 之上，它既不失灵活性同时能够大幅改进 etcd 整个系统的性能。
## 16.7 典型的使用场景介绍
元数据存储-Kubernetes

Server Discovery （Naming Service）

Distributed Coordination: leader election

Distributed Coordination 分布式系统并发控制
# 17. 深入理解etcd：etcd性能优化实践
## 17.1 etcd架构
etcd 集群划分成几个核心的部分：例如 Raft 层、 Storage 层，Storage 层内部又分为 treeIndex 层和 boltdb 底层持久化存储 key/value 层。它们的每一层都有可能造成 etcd 的性能损失。

首先来看 Raft 层，Raft 需要通过网络同步数据，网络 IO 节点之间的 RTT 和 / 带宽会影响 etcd 的性能。除此之外，WAL 也受到磁盘 IO 写入速度影响。

再来看 Storage 层，磁盘 IO fdatasync 延迟会影响 etcd 性能，索引层锁的 block 也会影响 etcd 的性能。除此之外，boltdb Tx 的锁以及 boltdb 本身的性能也将大大影响 etcd 的性能。

从其他方面来看，etcd 所在宿主机的内核参数和 grpc api 层的延迟，也将影响 etcd 的性能。
## 17.2 server端
### 17.2.1 硬件部署
server 端在硬件上需要足够的 CPU 和 Memory 来保障 etcd 的运行。其次，作为一个非常依赖于磁盘 IO 的数据库程序，etcd 需要 IO 延迟和吞吐量非常好的 ssd 硬盘，etcd 是一个分布式的 key/value 存储系统，网络条件对它也很重要。最后在部署上，需要尽量将它独立的部署，以防止宿主机的其他程序会对 etcd 的性能造成干扰。

etcd 官方推荐的配置要求信息：https://coreos.com/docs/latest/op-guide/hardware.html
### 17.2.2 软件
etcd 软件分成很多层：
- 首先是针对于 etcd 的内存索引层优化：优化内部锁的使用减少等待时间。 原来的实现方式是遍历内部引 BTree 使用的内部锁粒度比较粗，这个锁很大程度上影响了 etcd 的性能，新的优化减少了这一部分的影响，降低了延迟。
  具体可参照如下链接：https://github.com/coreos/etcd/pull/9511
- 针对于 lease 规模使用的优化：优化了 lease revoke 和过期失效的算法，将原来遍历失效 list 时间复杂度从 O(n) 降为 O(logn)，解决了 lease 规模化使用的问题。
  具体可参照如下链接：https://github.com/coreos/etcd/pull/9418
- 最后是针对于后端 boltdb 的使用优化：将后端的 batch size limit/interval 进行调整，这样就能根据不同的硬件和工作负载进行动态配置，这些参数以前都是固定的保守值。
  具体可参照如下链接：https://github.com/etcd-io/etcd/commit/3faed211e535729a9dc36198a8aab8799099d0f3
- 还有一点是由谷歌工程师优化的完全并发读特性：优化调用 boltdb tx 读写锁使用，提升读性能。
  具体可参照如下链接：https://github.com/etcd-io/etcd/pull/10523
### 17.2.3 基于 segregated hashmap 的 etcd 内部存储 freelist 分配回收新算法
由阿里贡献的一个性能优化，这个性能优化极大地提升了 etcd 内部存储的性能，CNCF文章：https://www.cncf.io/blog/2019/05/09/performance-optimization-of-etcd-in-web-scale-data-scenario/
## 17.3 client 端
etcd server 给客户端提供的几个 API：Put、Get、Watch、Transactions、Leases 很多个操作。保持客户端使用最佳实践，将保证你的 etcd 集群稳定高效运行。

针对于以上的客户端操作，我们总结了几个最佳实践调用：
- 针对于 Put 操作避免使用大 value，精简精简再精简，例如 K8s 下的 crd 使用；
- 其次，etcd 本身适用及存储一些不频繁变动的 key/value 元数据信息。因此客户端在使用上需要避免创建频繁变化的 key/value。这一点例如 K8s下对于新的 node 节点的心跳数据上传就遵循了这一实践；
- 最后，我们需要避免创建大量的 lease，尽量选择复用。例如在 K8s下，event 数据管理：相同 TTL 失效时间的 event 同样会选择类似的 lease 进行复用，而不是创建新的 lease。
# 18. kubernetes调度和资源管理
## 18.1 Kubernetes 调度过程
Kubernetes 集群提交一个 pod，它的调度过程：
- 假设我们已经写好了一个 yaml 文件，就是下图中的橙色圆圈 pod1，然后我们往 kube-ApiServer 里面提交这个 yaml 文件。此时 ApiServer 会先把这个待创建的请求路由给我们的 webhooks 的 Controlles 进行校验。
- 在通过校验之后，ApiServer 会在集群里面生成一个 pod，但此时生成的 pod，它的 nodeName 是空的，并且它的 phase 是 Pending 状态。在生成了这个 pod 之后，kube-Scheduler 以及 kubelet 都能 watch 到这个 pod 的生成事件，kube-Scheduler 发现这个 pod 的 nodeName 是空的之后，会认为这个 pod 是处于未调度状态。
- 接下来，它会把这个 pod 拿到自己里面进行调度，通过一系列的调度算法，包括一系列的过滤和打分的算法后，Schedule 会选出一台最合适的节点，并且把这一台节点的名称绑定在这个 pod 的 spec 上，完成一次调度的过程。
- 此时我们发现，pod 的 spec 上，nodeName 已经更新成了 Node1 这个 node，更新完 nodeName 之后，在 Node1 上的这台 kubelet 会 watch 到这个 pod 是属于自己节点上的一个 pod。
- 然后它会把这个 pod 拿到节点上进行操作，包括创建一些容器 storage 以及 network，最后等所有的资源都准备完成，kubelet 会把状态更新为 Running，这样一个完整的调度过程就结束了。

调度过程：它其实就是在做一件事情，就是把 pod 放到合适的 node 上。这里给出了几点合适定义的特点：
- 1、首先要满足 pod 的资源要求；
- 2、其次要满足 pod 的一些特殊关系的要求；
- 3、再次要满足 node 的一些限制条件的要求；
- 4、最后还要做到整个集群资源的合理利用。
## 18.2 Kubernetes 基础调度力
### 18.2.1 基础资源类型
四大类的基础资源：
- 第一类是 CPU 资源；
- 第二类是 memory；
- 第三类是 ephemeral-storage，一种临时存储； 
- 第四类是通用的扩展资源，比如说像 GPU。

在扩展资源上，Kubernetes 有一个要求，即扩展资源必须是整数的，所以我们没法申请到 0.5 的 GPU 这样的资源，只能申请 1 个 GPU 或者 2 个 GPU。
### 18.2.2 Pod QoS 类型
Qos 全称是 Quality of Service，它其实是 Kubernetes 用来表达一个 pod 在资源能力上的服务质量的标准，Kubernetes 提供了三类的 Qos Class:

- 第一类是 Guaranteed，它是一类高的 Qos Class，一般用 Guaranteed 来为一些需要资源保障能力的 pod 进行配置；
- 第二类是 Burstable，它其实是中等的一个 Qos label，一般会为一些希望有弹性能力的 pod 来配置 Burstable；
- 第三类是 BestEffort，通过名字我们也知道，它是一种尽力而为式的服务质量。

用户自己提交的时候，是没法定义自己的 Qos 等级，所以将这种方式称之为隐性的 Qos class 用法。
### 18.2.3 Pod QoS 配置
三种 Qos level：
- Guaranteed Pod，基础资源（就是包括 CPU 和 memory），必须它的 request==limit，其他的资源可以不相等。
- Burstable Pod，范围比较宽泛，它只要满足 CPU/Memory 的 request 和 limit 不相等。
- BestEffort Pod，必须是所有资源的 request/limit 都不填。

当我们开启了 kubelet 的一个特性，叫 cpu-manager-policy=static 的时候，它会对 Guaranteed Pod 进行绑核。
### 18.2.4 资源 Quota
Kubernetes 给我们提供了一个能力叫：ResourceQuota 方法。它可以做到限制 namespace 资源用量。我们可以用 ResourceQuota 方法来做到限制每一个 namespace 的资源用量，从而保证其他用户的资源使用。
## 18.2.5 小结：如何满足 Pod 资源要求？
上面介绍完了基础资源的使用方式，也就是我们做到了如何满足 Pod 资源要求。下面做一个小结：
- Pod 要配置合理的资源要求
  - CPU/Memory/EphemeralStorage/GPU
- 通过 Request 和 Limit 来为不同业务特点的 Pod 选择不同的 QoS
  - Guaranteed：敏感型，需要业务保障
  - Burstable：次敏感型，需要弹性业务
  - BestEffort：可容忍性业务
- 为每个 NS 配置 ResourceQuota 来防止过量使用，保障其他人的资源可用
## 18.3 如何满足 Pod 与 Pod 关系要求？
接下来给大家介绍一下 Pod 的关系调度，首先是 Pod 和 Pod 的关系调度。我们在平时使用中可能会遇到一些场景：比如说一个 Pod 必须要和另外一个 Pod 放在一起，或者不能和另外一个 Pod 放在一起。

在这种要求下， Kubernetes 提供了两类能力：
- 第一类能力称之为 Pod 亲和调度：PodAffinity；
- 第二类就是 Pod 反亲和调度：PodAntAffinity。
### 18.3.1 Pod 亲和调度
- podAffinity：required， 严格的亲和调度，我们叫做尝试亲和调度
- podAffinity：preferred， 优先亲和调度
### 18.3.2 Pod 反亲和调度
- podAntiAffinity：required， 强制反亲和
- podAntiAffinity：preferred， 优先反亲和
## 18.4 如何满足 Pod 与 Node 关系调度
Pod 与 Node 的关系调度又称之为 Node 亲和调度，主要给大家介绍两类使用方法。
### 18.4.1 NodeSelector
强制调度
### 18.4.2 NodeAffinity
- 第一类是 required，必须调度到某一类 Node 上；
- 第二类是 preferred，就是优先调度到某一类 Node 上。
### 18.4.3 Node 标记/容忍
还有第三类调度，可以通过给 Node 打一些标记，来限制 Pod 调度到某些 Node 上。Kubernetes 把这些标记称之为 Taints，它的字面意思是污染。taints 内容包括 key、value、effect：
- key 就是配置的键值
- value 就是内容
- effect 是标记了这个 taints 行为是什么

目前 Kubernetes 里面有三个 taints 行为：
- NoSchedule 禁止新的 Pod 调度上来；
- PreferNoSchedul 尽量不调度到这台；
- NoExecute 会 evict 没有对应 toleration 的 Pods，并且也不会调度新的上来。这个策略是非常严格的，大家在使用的时候要小心一点。
### 18.4.4 小结
我们已经介绍完了 Pod/Node 的特殊关系和条件调度，来做一下小结。

首先假如有需求是处理 Pod 与 Pod 的时候，比如 Pod 和另一个 Pod 有亲和的关系或者是互斥的关系，可以给它们配置下面的参数：
- PodAffinity
- PodAntiAffinity

假如存在 Pod 和 Node 有亲和关系，可以配置下面的参数：
- NodeSelector
- NodeAffinity

假如有些 Node 是限制某些 Pod 调度的，比如说一些故障的 Node，或者说是一些特殊业务的 Node，可以配置下面的参数：
- Node -- Taints
- Pod -- Tolerations
## 18.5 Kubernetes 高级调度能力
### 18.5.1 优先级调度
优先级调度和抢占，主要概念有：
- Priority
- Preemption

通常的策略有两类：
- 先到先得策略 (FIFO) -简单、相对公平，上手快
- 优先级策略 (Priority) - 符合日常公司业务特点
### 18.5.2 优先级调度配置
使用：
需要创建一个 priorityClass，然后再为每个 Pod 配置上不同的 priorityClassName，这样就完成了优先级以及优先级调度的配置。

内置优先级配置：
默认的优先级。如 DefaultpriorityWhenNoDefaultClassExistis，如果集群中没有配置 DefaultpriorityWhenNoDefaultClassExistis，那所有的 Pod 关于此项数值都会被设置成 0。

另一个内置优先级是用户可配置最大优先级限制：HighestUserDefinablePriority = 10000000000(10 亿)

系统级别优先级：SystemCriticalPriority = 20000000000(20 亿)

内置系统级别优先级：
- system-cluster-critical
- system-node-critical

这就是优先级调度的基本配置以及内置的优先级配置。
### 18.5.3 小结
简单介绍了一下调度的高级策略，在集群资源紧张的时候也能合理调度资源。我们回顾一下做了哪些事情：
- 创建自定义的一些优先级类别 (PriorityClass)； 
- 给不同类型 Pods 配置不同的优先级 (PriorityClassName)； 
- 通过组合不同类型 Pods 运行和优先级抢占让集群资源和调度弹性起来。
# 19. 调度器的调度流程和算法介绍
## 19.1 调度流程
调度器启动时会通过配置文件 File，或者是命令行参数，或者是配置好的 ConfigMap，来指定调度策略。指定要用哪些过滤器 (Predicates)、打分器 (Priorities) 以及要外挂哪些外部扩展的调度器 (Extenders)，和要使用的哪些 Schedule 的扩展点 (Plugins)。

启动的时候会通过 kube-apiserver 去 watch 相关的数据，通过 Informer 机制将调度需要的数据 ：Pod 数据、Node 数据、存储相关的数据，以及在抢占流程中需要的 PDB 数据，和打散算法需要的 Controller-Workload 数据。

调度算法的流程大概是这样的：通过 Informer 去 watch 到需要等待的 Pod 数据，放到队列里面，通过调度算法流程里面，会一直循环从队列里面拿数据，然后经过调度流水线。

调度流水线 (Schedule Pipeline) 主要有三个组成部分：

调度器的调度流程
- Wait 流程
- Bind 流程

在整个循环过程中，会有一个串行化的过程：从调度队列里面拿到一个 Pod 进入到 Schedule Theread 流程中，通过 Pre Filter--Filter--Post Filter--Score(打分)-Reserve，最后 Reserve 对账本做预占用。

基本调度流程结束后，会把这个任务提交给 Wait Thread 以及 Bind Thread，然后 Schedule Theread 继续执行流程，会从调度队列中拿到下一个 Pod 进行调度。

调度完成后，会去更新调度缓存 (Schedule Cache)，如更新 Pod 数据的缓存，也会更新 Node 数据。以上就是大概的调度流程。
## 19.2 调度算法实现
### 19.2.1 Predicates (过滤器)
首先介绍一下过滤器，它可以分为四类：
- 存储相关
- Pode 和 Node 匹配相关
- Pod 和 Pod 匹配相关
- Pod 打散相关
### 19.2.2 Priorities
接下来看一下打分算法，打分算法主要解决的问题就是集群的碎片、容灾、水位、亲和、反亲和等。

按照类别可以分为四大类：
- Node 水位
- Pod 打散 (topp,service,controller)
- Node 亲和&反亲和
- Pod 亲和&反亲和
### 19.2.3 Pod 打散
- SelectorSpreadPriority
- ServiceSpreadingPriority
- EvenPodsSpreadPriority
### 19.2.4 Node 亲和&反亲和
- NodeAffinityPriority
- ServiceAntiAffinity
- NodeLabelPrioritizer
- ImageLocalityPriority
### 19.2.5 Pod 亲和&反亲和
- InterPodAffinityPriority
- NodePreferAvoidPodsPriority
## 19.3 如何配置调度器
怎么启动一个调度器，这里有两种情况：
- 第一种我们可以通过默认配置启动调度器，什么参数都不指定；
- 第二种我们可以通过指定配置的调度文件。
## 19.4 如何扩展调度器
- Scheduler Extender
- Scheduler Framework
# 20. GPU管理和Device Plugin工作机制
## 20.1 背景
希望能在 Kubernetes 集群上运行 TensorFlow 等机器学习框架，深度学习所依赖的异构设备及英伟达的 GPU 支持。具体来说是三个方面：
- 加速部署：通过容器构想避免重复部署机器学习复杂环境；
- 提升集群资源使用率：统一调度和分配集群资源；
- 保障资源独享：利用容器隔离异构设备，避免互相影响。
## 20.2 GPU 的容器化
在容器环境下使用 GPU 应用，实际上不复杂。主要分为两步：
- 构建支持 GPU 的容器镜像；
- 利用 Docker 将该镜像运行起来，并且把 GPU 设备和依赖库映射到容器中。
## 20.3 Kubernetes 的 GPU 管理
如何部署 GPU Kubernetes：
- 首先安装 Nvidia 驱动；
- 第二步通过 yum 源，安装 Nvidia Docker2；
- 第三步是部署 Nvidia Device Plugin。

使用 GPU 的 yaml 样例：需要在 Pod 资源配置的 limit 字段中指定 nvidia.com/gpu 使用 GPU 的数量
## 20.4 工作原理
Kubernetes 本身是通过插件扩展的机制来管理 GPU 资源的，具体来说这里有两个独立的内部机制。
- 第一个是 Extend Resources
- Device Plugin Framework 允许第三方设备提供商以外置的方式对设备进行全生命周期的管理
# 21. kubernetes存储架构及插件使用
## 21.1 Kubernetes 存储体系架构
- PV Controller: 负责 PV/PVC 的绑定、生命周期管理，并根据需求进行数据卷的 Provision/Delete 操作；
- AD Controller： 负责存储设备的 Attach/Detach 操作，将设备挂载到目标节点；
- Volume Manager： 管理卷的 Mount/Unmount 操作、卷设备的格式化以及挂载到一些公用目录上的操作；
- Volume Plugins：它主要是对上面所有挂载功能的实现。
- Scheduler： 实现对 Pod 的调度能力，会根据一些存储相关的的定义去做一些存储相关的调度。
## 21.2 Flexvolume 介绍及使用
Flexvolume 是 Volume Plugins 的一个扩展，主要实现 Attach/Detach/Mount/Unmount 这些接口。我们知道这些功能本是由 Volume Plugins 实现的，但是对于某些存储类型，我们需要将其扩展到 Volume Plugins 以外，所以我们需要把接口的具体实现放到外面。
## 21.3 CSI 介绍及使用
和 Flexvolume 类似，CSI 也是为第三方存储提供数据卷实现的抽象接口。

有了 Flexvolume，为何还要 CSI 呢？

Flexvolume 只是给 kubernetes 这一个编排系统来使用的，而 CSI 可以满足不同编排系统的需求，比如 Mesos，Swarm。

其次 CSI 是容器化部署，可以减少环境依赖，增强安全性，丰富插件的功能。我们知道，Flexvolume 是在 host 空间一个二进制文件，执行 Flexvolum 时相当于执行了本地的一个 shell 命令，这使得我们在安装 Flexvolume 的时候需要同时安装某些依赖，而这些依赖可能会对客户的应用产生一些影响。因此在安全性上、环境依赖上，就会有一个不好的影响。

# 22. 有状态应用编排：StatefulSet
## 22.1 背景
- Pod之间固定的网络标识
- 每个Pod独立的存储盘
- 应用发布时，按照固定顺序升级Pod
## 22.2 架构设计
StatefulSet 可能会创建三种类型的资源。
- ControllerRevision：通过这个资源，StatefulSet 可以很方便地管理不同版本的 template 模板。
- PVC：如果在 StatefulSet 中定义了 volumeClaimTemplates，StatefulSet 会在创建 Pod 之前，先根据这个模板创建 PVC，并把 PVC 加到 Pod volume 中。
- Pod：StatefulSet 按照顺序创建、删除、更新 Pod，每个 Pod 有唯一的序号。
# 23. kubernetesAPI编程范式
## 23.1 背景
在 Kubernetes 里面， API 编程范式也就是 Custom Resources Definition(CRD)。

随着 Kubernetes 使用的越来越多，用户自定义资源的需求也会越来越多。而 Kubernetes 提供的聚合各个子资源的功能，已经不能满足日益增长的广泛需求了。用户希望提供一种用户自定义的资源，把各个子资源全部聚合起来。但 Kubernetes 原生资源的扩展和使用比较复杂，因此诞生了用户自定义资源这么一个功能。
## 23.2 CRD
- 带有校验的 CRD
- 带有状态字段的 CRD
## 23.3 架构设计
只定义一个 CRD 其实没有什么作用，它只会被 API Server 简单地计入到 etcd 中。如何依据这个 CRD 定义的资源和 Schema 来做一些复杂的操作，则是由 Controller，也就是控制器来实现的。

Controller 其实是 Kubernetes 提供的一种可插拔式的方法来扩展或者控制声明式的 Kubernetes 资源。它是 Kubernetes 的大脑，负责大部分资源的控制操作。以 Deployment 为例，它就是通过 kube-controller-manager 来部署的。

比如说声明一个 Deployment 有 replicas、有 2 个 Pod，那么 kube-controller-manager 在观察 etcd 时接收到了该请求之后，就会去创建两个对应的 Pod 的副本，并且它会去实时地观察着这些 Pod 的状态，如果这些 Pod 发生变化了、回滚了、失败了、重启了等等，它都会去做一些对应的操作。
# 24. kubernetesAPI变成利器：Operator和OperatorFramework
## 24.1 概述
operator: operator 是描述、部署和管理 kubernetes 应用的一套机制，从实现上来说，可以将其理解为 CRD 配合可选的 webhook 与 controller 来实现用户业务逻辑，即 operator = CRD + webhook + controller。
## 24.2 operator framework实战
主流的 operator framework 主要有两个：kubebuilder 和 operator-sdk。
# 25. kubernetes网络模型进阶
## 25.1 背景
容器网络发端于 Docker 的网络。Docker 使用了一个比较简单的网络模型，即内部的网桥加内部的保留 IP。这种设计的好处在于容器的网络和外部世界是解耦的，无需占用宿主机的 IP 或者宿主机的资源，完全是虚拟的。它的设计初衷是：当需要访问外部世界时，会采用 SNAT 这种方法来借用 Node 的 IP 去访问外面的服务。比如容器需要对外提供服务的时候，所用的是 DNAT 技术，也就是在 Node 上开一个端口，然后通过 iptable 或者别的某些机制，把流导入到容器的进程上以达到目的。 该模型的问题在于，外部网络无法区分哪些是容器的网络与流量、哪些是宿主机的网络与流量。

Kubernetes 提出了这样一种机制：即每一个 Pod，也就是一个功能聚集小团伙应有自己的“身份证”，或者说 ID。在 TCP 协议栈上，这个 ID 就是 IP。 这个 IP 是真正属于该 Pod 的。
## 25.2 Pod如何访问外网
- 协议层次
- 网络拓扑
## 25.3 Service工作原理
Service 其实是一种负载均衡 (Load Balance) 的机制。我们认为它是一种用户侧(Client Side) 的负载均衡，也就是说 VIP 到 RIP 的转换在用户侧就已经完成了，并不需要集中式地到达某一个 NGINX 或者是一个 ELB 这样的组件来进行决策。

分类：
- ClusterIP
- NodePort
- LoadBalancer
- ExternalName
# 26. 理解CNI和CNI插件
# 27. kubernetes安全之访问控制
# 28. 理解容器运行时接口CRI
# 29. 安全容器技术
# 30. 理解RuntimeClass与使用多容器运行时
